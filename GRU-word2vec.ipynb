{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    data_df = pd.read_csv('train.tsv', sep='\\t')\n",
    "    x = data_df['Phrase'].values\n",
    "    y = data_df['Sentiment'].values\n",
    "    print('training data\\'s len:', x.shape[0])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testing_data():\n",
    "    data_df = pd.read_csv('test.tsv', sep='\\t')\n",
    "    x = data_df['Phrase'].values\n",
    "    print('testing data\\'s len:', x.shape[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data's len: 156060\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data's len: 66292\n"
     ]
    }
   ],
   "source": [
    "x_test = load_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'\n",
      " 'A series of escapades demonstrating the adage that what is good for the goose'\n",
      " 'A series' 'A' 'series']\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An intermittently pleasing but mostly routine effort .'\n",
      " 'An intermittently pleasing but mostly routine effort' 'An'\n",
      " 'intermittently pleasing but mostly routine effort'\n",
      " 'intermittently pleasing but mostly routine']\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ub/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ub/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(x_train) + list(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seqs = tokenizer.texts_to_sequences(list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 315, 3, 16573, 7660, 1, 8313, 9, 53, 8, 47, 13, 1, 3940, 8, 187, 47, 13, 1, 13024, 61, 3, 89, 592, 12156, 19, 617, 3, 89, 2810, 5, 52, 3, 2, 42], [2, 315, 3, 16573, 7660, 1, 8313, 9, 53, 8, 47, 13, 1, 3940], [2, 315], [2], [315]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_seqs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_paded = pad_sequences(x_train_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 49)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_paded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     2   315     3 16573  7660     1  8313     9    53     8\n",
      "     47    13     1  3940     8   187    47    13     1 13024    61     3\n",
      "     89   592 12156    19   617     3    89  2810     5    52     3     2\n",
      "     42]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     2\n",
      "    315     3 16573  7660     1  8313     9    53     8    47    13     1\n",
      "   3940]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     2\n",
      "    315]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      2]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    315]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_paded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return x[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_shuffled, y_train_shuffled = shuffle(x_train_paded, \n",
    "                                             y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0 1293  364    4 5419]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0 3429 9076   58  391    4 5730  952    5  125  154 1384\n",
      "     7    1  498    4  198   45 1827]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0  829   90 9404    5 1702]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   76  539 3207]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0  877   10    6   59  478   27    5  146\n",
      "  2023   13   88   22 2804   45   12]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_shuffled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_shuffled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('word2vec.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(word2idx) + 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'the' in wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in word2idx.items():\n",
    "    if word in wv.vocab:\n",
    "        embeddings[idx] = wv.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172    0.043953\n",
      "  -0.39140999  0.3344     -0.57545     0.087459    0.28786999 -0.06731\n",
      "   0.30906001 -0.26383999 -0.13231    -0.20757     0.33395001 -0.33848\n",
      "  -0.31742999 -0.48335999  0.1464     -0.37303999  0.34577     0.052041\n",
      "   0.44946    -0.46970999  0.02628    -0.54154998 -0.15518001 -0.14106999\n",
      "  -0.039722    0.28277001  0.14393     0.23464    -0.31020999  0.086173\n",
      "   0.20397     0.52623999  0.17163999 -0.082378   -0.71787    -0.41531\n",
      "   0.20334999 -0.12763     0.41367     0.55186999  0.57907999 -0.33476999\n",
      "  -0.36559001 -0.54856998 -0.062892    0.26583999  0.30204999  0.99774998\n",
      "  -0.80480999 -3.0243001   0.01254    -0.36941999  2.21670008  0.72201002\n",
      "  -0.24978     0.92136002  0.034514    0.46744999  1.10790002 -0.19358\n",
      "  -0.074575    0.23353    -0.052062   -0.22044     0.057162   -0.15806\n",
      "  -0.30798    -0.41624999  0.37972     0.15006    -0.53211999 -0.20550001\n",
      "  -1.25259995  0.071624    0.70564997  0.49744001 -0.42063001  0.26148\n",
      "  -1.53799999 -0.30223    -0.073438   -0.28312001  0.37103999 -0.25217\n",
      "   0.016215   -0.017099   -0.38984001  0.87423998 -0.72569001 -0.51058\n",
      "  -0.52028    -0.1459      0.82779998  0.27061999]\n",
      " [-0.27085999  0.044006   -0.02026    -0.17395     0.6444      0.71213001\n",
      "   0.35510001  0.47138    -0.29637     0.54426998 -0.72294003 -0.0047612\n",
      "   0.040611    0.043236    0.29729     0.10725     0.40156001 -0.53662002\n",
      "   0.033382    0.067396    0.64556003 -0.085523    0.14103     0.094539\n",
      "   0.74947    -0.19400001 -0.68739003 -0.41740999 -0.22807001  0.12\n",
      "  -0.48999     0.80944997  0.045138   -0.11898     0.20161     0.39276001\n",
      "  -0.20121001  0.31354001  0.75304002  0.25907001 -0.11566    -0.029319\n",
      "   0.93498999 -0.36067     0.52420002  0.23706     0.52714998  0.22869\n",
      "  -0.51958001 -0.79348999 -0.20367999 -0.50186998  0.18748     0.94282001\n",
      "  -0.44834    -3.67919993  0.044183   -0.26751     2.19970012  0.241\n",
      "  -0.033425    0.69553    -0.64472002 -0.0072277   0.89574999  0.20015\n",
      "   0.46493     0.61932999 -0.1066      0.08691    -0.4623      0.18262\n",
      "  -0.15849     0.020791    0.19373     0.063426   -0.31672999 -0.48177001\n",
      "  -1.38479996  0.13669001  0.96859002  0.049965   -0.27379999 -0.035686\n",
      "  -1.05770004 -0.24467     0.90366    -0.12442     0.080776   -0.83401\n",
      "   0.57200998  0.088945   -0.42532    -0.018253   -0.079995   -0.28580999\n",
      "  -0.01089    -0.4923      0.63687003  0.23642001]\n",
      " [-0.1529     -0.24279     0.89837003  0.16996001  0.53516001  0.48784\n",
      "  -0.58825999 -0.17982    -1.35810006  0.42541     0.15377     0.24214999\n",
      "   0.13474     0.41192999  0.67043    -0.56418002  0.42985001 -0.012183\n",
      "  -0.11677     0.31781     0.054177   -0.054273    0.35516    -0.30241001\n",
      "   0.31434    -0.33846     0.71714997 -0.26855001 -0.15837    -0.47466999\n",
      "   0.051581   -0.33252001  0.15003    -0.12989999 -0.54617    -0.37843001\n",
      "   0.64261001  0.82187003 -0.080006    0.078479   -0.96976    -0.57740998\n",
      "   0.56490999 -0.39873001 -0.057099    0.19743     0.065706   -0.48091999\n",
      "  -0.20125    -0.40834001  0.39456001 -0.02642    -0.11838     1.01199996\n",
      "  -0.53171003 -2.74740005 -0.042981   -0.74848998  1.75740004  0.59085\n",
      "   0.04885     0.78267002  0.38497001  0.42096999  0.67882001  0.10337\n",
      "   0.63279998 -0.026595    0.58647001 -0.44332001  0.33057001 -0.12022\n",
      "  -0.55645001  0.073611    0.20915     0.43395001 -0.012761    0.089874\n",
      "  -1.79910004  0.084808    0.77112001  0.63104999 -0.90684998  0.60325998\n",
      "  -1.75150001  0.18595999 -0.50686997 -0.70203     0.66578001 -0.81304002\n",
      "   0.18712001 -0.018488   -0.26756999  0.727      -0.59363002 -0.34839001\n",
      "  -0.56094003 -0.59100002  1.00390005  0.20664001]\n",
      " [-0.071953    0.23127     0.023731   -0.50638002  0.33923     0.19589999\n",
      "  -0.32943001  0.18364    -0.18057001  0.28963     0.20448001 -0.54960001\n",
      "   0.27399001  0.58327001  0.20468    -0.49228001  0.19973999 -0.070237\n",
      "  -0.88049001  0.29484999  0.14071    -0.1009      0.99449003  0.36973\n",
      "   0.44554001  0.28997999 -0.1376     -0.56365001 -0.029365   -0.4122\n",
      "  -0.25268999  0.63181001 -0.44767001  0.24363001 -0.10813     0.25163999\n",
      "   0.46967     0.37549999 -0.23613    -0.14128999 -0.44536999 -0.65736997\n",
      "  -0.042421   -0.28636    -0.28810999  0.063766    0.20281    -0.53542\n",
      "   0.41306999 -0.59722    -0.38613999  0.19389001 -0.17809001  1.66180003\n",
      "  -0.011819   -2.3736999   0.058427   -0.26980001  1.2823      0.81924999\n",
      "  -0.22322001  0.72931999 -0.053211    0.43507001  0.85010999 -0.42934999\n",
      "   0.92663997  0.39050999  1.05850005 -0.24561    -0.18265    -0.53280002\n",
      "   0.059518   -0.66018999  0.18990999  0.28836    -0.24339999  0.52784002\n",
      "  -0.65762001 -0.14081     1.04910004  0.51340002 -0.23816     0.69894999\n",
      "  -1.4813     -0.24869999 -0.17936    -0.059137   -0.08056    -0.48782\n",
      "   0.014487   -0.62589997 -0.32367     0.41861999 -1.08070004  0.46742001\n",
      "  -0.49930999 -0.71894997  0.86894     0.19539   ]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.add(Embedding(embeddings.shape[0], \n",
    "                        100, \n",
    "                        weights=[embeddings], \n",
    "                        trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "gru_model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156060/156060 [==============================] - 373s 2ms/step - loss: 1.0466 - acc: 0.5731\n",
      "Epoch 2/10\n",
      "156060/156060 [==============================] - 355s 2ms/step - loss: 0.9559 - acc: 0.6043\n",
      "Epoch 3/10\n",
      "156060/156060 [==============================] - 376s 2ms/step - loss: 0.9303 - acc: 0.6138\n",
      "Epoch 4/10\n",
      "156060/156060 [==============================] - 378s 2ms/step - loss: 0.9087 - acc: 0.6237\n",
      "Epoch 5/10\n",
      "156060/156060 [==============================] - 334s 2ms/step - loss: 0.8932 - acc: 0.6301\n",
      "Epoch 6/10\n",
      "156060/156060 [==============================] - 332s 2ms/step - loss: 0.8785 - acc: 0.6364\n",
      "Epoch 7/10\n",
      "156060/156060 [==============================] - 330s 2ms/step - loss: 0.8670 - acc: 0.6407\n",
      "Epoch 8/10\n",
      "156060/156060 [==============================] - 329s 2ms/step - loss: 0.8572 - acc: 0.6448\n",
      "Epoch 9/10\n",
      "156060/156060 [==============================] - 328s 2ms/step - loss: 0.8492 - acc: 0.6485\n",
      "Epoch 10/10\n",
      "156060/156060 [==============================] - 331s 2ms/step - loss: 0.8405 - acc: 0.6518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f7a04a470>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.fit(x_train_shuffled, y_train_shuffled, batch_size=256, \n",
    "              epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_seqs = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_paded = pad_sequences(x_test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66292/66292 [==============================] - 135s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = gru_model.predict_classes(x_test_paded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Sentiment'] = test_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('gru-word2vec.csv', columns=['PhraseId', 'Sentiment'], \n",
    "               index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
